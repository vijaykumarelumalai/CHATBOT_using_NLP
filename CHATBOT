import io
import random
import string # to process standard python strings
import warnings
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import warnings
warnings.filterwarnings('ignore')

import nltk
from nltk.stem import WordNetLemmatizer
nltk.download('popular', quiet=True) # for downloading packages

# uncomment the following only the first time
#nltk.download('punkt') # first-time use only
#nltk.download('wordnet') # first-time use only

# Predefined corpus
raw = """Hello! I am a chatbot. I can help you with your queries about chatbots.
Chatbots are software applications that mimic human conversation.
They are used in various applications such as customer service, information retrieval, and more.
Chatbots can be rule-based or use artificial intelligence techniques.
The goal of a chatbot is to simulate a human-like interaction with users.
Chatbots can understand natural language and provide appropriate responses.
There are many different types of chatbots, including virtual assistants, conversational agents, and more.
Chatbots can be integrated into websites, messaging platforms, and mobile apps.
They can help automate repetitive tasks and improve user experience.
Some popular examples of chatbots are Siri, Alexa, and Google Assistant.
Chatbots can be built using various frameworks and tools.
Developing a chatbot involves designing conversational flows, implementing natural language processing, and more.
Chatbots are becoming increasingly popular and are being used in a wide range of industries.
If you have any questions about chatbots, feel free to ask!"""

raw = raw.lower()

# Tokenization
sent_tokens = nltk.sent_tokenize(raw) # converts to list of sentences 
word_tokens = nltk.word_tokenize(raw) # converts to list of words

# Preprocessing
lemmer = WordNetLemmatizer()
def LemTokens(tokens):
    return [lemmer.lemmatize(token) for token in tokens]
remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)
def LemNormalize(text):
    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))

# Keyword Matching
GREETING_INPUTS = ("hello", "hi", "greetings", "sup", "what's up", "hey")
GREETING_RESPONSES = ["hi", "hey", "*nods*", "hi there", "hello", "I am glad! You are talking to me"]

def greeting(sentence):
    """If user's input is a greeting, return a greeting response"""
    for word in sentence.split():
        if word.lower() in GREETING_INPUTS:
            return random.choice(GREETING_RESPONSES)

# Generating response
def response(user_response):
    robo_response = ''
    sent_tokens.append(user_response)
    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')
    tfidf = TfidfVec.fit_transform(sent_tokens)
    vals = cosine_similarity(tfidf[-1], tfidf)
    idx = vals.argsort()[0][-2]
    flat = vals.flatten()
    flat.sort()
    req_tfidf = flat[-2]
    if req_tfidf == 0:
        robo_response = robo_response + "I am sorry! I don't understand you"
    else:
        robo_response = robo_response + sent_tokens[idx]
    sent_tokens.pop(-1)
    return robo_response

flag = True
print("ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!")
while flag:
    user_response = input().lower()
    if user_response != 'bye':
        if user_response in ('thanks', 'thank you'):
            flag = False
            print("ROBO: You are welcome..")
        else:
            if greeting(user_response) is not None:
                print("ROBO: " + greeting(user_response))
            else:
                print("ROBO: " + response(user_response))
    else:
        flag = False
        print("ROBO: Bye! Take care..")

